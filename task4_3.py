# -*- coding: utf-8 -*-
"""Task4_3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tFu3qsS0eXc-HxoZUC6rwMaE3ASxS_pD
"""

from google.colab import userdata
os.environ["HF_TOKEN"] = userdata.get('Hftoken')

from openai import OpenAI
import os

client = OpenAI(
    base_url="https://router.huggingface.co/v1",
    api_key=os.environ["HF_TOKEN"],
)

# Prompt template
template = "Explain {topic} in a {tone} way for a {audience}."

# Prompt variations
prompts = [
    template.format(topic="Artificial Intelligence", tone="simple", audience="school student"),
    template.format(topic="Artificial Intelligence", tone="technical", audience="computer science student"),
    template.format(topic="Artificial Intelligence", tone="real-world", audience="working professional"),
]

# Test variations
for prompt in prompts:
    response = client.chat.completions.create(
        model="deepseek-ai/DeepSeek-V3.2:novita",
        messages=[{"role": "user", "content": prompt}],
    )
    print("Prompt:", prompt)
    print("Response:", response.choices[0].message.content)
    print("-" * 50)